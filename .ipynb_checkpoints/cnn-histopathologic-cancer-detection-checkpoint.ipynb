{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\n!pip install 'torchsummary'\n\nimport os\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom PIL import Image\nfrom tqdm import tqdm\n%matplotlib inline\n\n# Visual adjustment\nnp.set_printoptions(precision=6, linewidth=1024, suppress=True)\nplt.style.use('seaborn')\nsns.set(style='darkgrid', context='notebook',font_scale=1.10)\n\n# Pytorch\nimport torch\ngpu_available = torch.cuda.is_available()\nprint('Using Pytorch version %s. GPU %s available' % (torch.__version__, \"IS\" if gpu_available else \"IS **NOT**\"))\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Dataset\nfrom torchsummary import summary\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n\n# to ensure that you get consistent results\n# @see: https://discuss.pytorch.org/t/reproducibility-over-different-machines/63047\nseed = 123\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed);\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.enabled = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA: Exploratory Data Analysis\nFirst, let's check the provided csv file.","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/histopathologic-cancer-detection/'\ndf = pd.read_csv(INPUT_DIR + 'train_labels.csv')\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking if there were any null;\nlen(df[df.isnull().any(axis=1)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's check the distribution of target labels","metadata":{}},{"cell_type":"code","source":"ax = df['label'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n\nax.set_xticks([0, 1])\nax.set_xticklabels(['0: Benign', '1: Malignant'])\nplt.xticks(rotation=0)\nax.set_xlabel('Label')\nax.set_ylabel('Count')\nax.set_title('Label Distribution')\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's save the benign & malignant counts\nnum_benign, num_malignant = np.bincount(df['label'])\nprint(f\"Found {num_benign} Benign cases and {num_malignant} Malignant cases in dataset\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing\n","metadata":{}},{"cell_type":"markdown","source":"## Function: Generating Subset of Dataset \n\nWe will split our 'Train' data into three subset, namely X_train, X_val, and X_test.  \nIn the cell below, 'get_data' function is to generate meta data from the provided csv file, to attach/call the actual image dataset.","metadata":{}},{"cell_type":"code","source":"def get_data():\n    # plot the label distribusion to check the label balance  \n    df = pd.read_csv(INPUT_DIR + 'train_labels.csv')\n    ax = df['label'].value_counts().plot(kind='bar', color=['blue', 'orange'])\n    ax.set_xticks([0, 1])\n    ax.set_xticklabels(['0: Benign', '1: Malignant'])\n    plt.xticks(rotation=0)\n    ax.set_xlabel('Label')\n    ax.set_ylabel('Count')\n    ax.set_title('Diagnosis')\n    plt.show()\n    \n    # Shuffle the dataframe\n    df = df.sample(frac=1).reset_index(drop=True) # frac=1: \n    print(f'Found {len(df[df.isnull().any(axis=1)])} after shuffling')\n    \n    # split into train/cross-val/test datasets (use stratify so we get a similar distribution)\n    image_ids, labels = df['id'], df['label']\n    X_train, X_test, y_train, y_test = \\\n      train_test_split(image_ids, labels, test_size=0.30, random_state=seed, stratify=labels)\n    X_val, X_test, y_val, y_test = \\\n      train_test_split(X_test, y_test, test_size=0.20, random_state=seed, stratify=y_test)\n    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n\n    # prepare the image paths\n    X_train_image_paths = [os.path.join(INPUT_DIR, 'train', image_id + '.tif') for image_id in X_train.values]\n    X_val_image_paths = [os.path.join(INPUT_DIR, 'train', image_id + '.tif') for image_id in X_val.values]\n    X_test_image_paths = [os.path.join(INPUT_DIR, 'train', image_id + '.tif') for image_id in X_test.values]\n\n    # These will be meta data attaching to the actual image data to feed to the data loader\n    return (X_train_image_paths, y_train.values, X_train.values), \\\n           (X_val_image_paths, y_val.values, X_val.values), \\\n           (X_test_image_paths, y_test.values, X_test.values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Function: Displaying Sample Images ","metadata":{}},{"cell_type":"code","source":"def display_sample(sample_images, sample_labels, sample_predictions=None, grid_shape=(8, 8), \n                   plot_title=None, fig_size=None):\n    \"\"\" \n    display a random selection of images & corresponding labels, optionally with predictions\n    The display is laid out in a grid of num_rows x num_col cells\n    \"\"\"\n    num_rows, num_cols = grid_shape\n    assert len(sample_images) == num_rows * num_cols\n\n    # a dict to help encode/decode the labels \n    LABELS = {\n        1: 'Malignant',\n        0: 'Benign'\n    }\n\n    with sns.axes_style(\"whitegrid\"):\n        sns.set_context(\"notebook\", font_scale=1.1)\n        sns.set_style({\"font.sans-serif\": [\"Verdana\", \"Arial\", \"Calibri\", \"DejaVu Sans\"]})\n        \n        f, ax = plt.subplots(num_rows, num_cols, figsize=((20, 20) if fig_size is None else fig_size),\n                            gridspec_kw={\"wspace\": 0.02, \"hspace\": 0.25}, squeeze=True)\n        # fig = ax[0].get_figure()\n        f.tight_layout()\n        f.subplots_adjust(top=0.95)\n\n        for r in range(num_rows):\n            for c in range(num_cols):\n                image_index = r * num_cols + c\n                ax[r, c].axis(\"off\")\n\n                # show selected image\n                sample_image = sample_images[image_index]\n                # got image as (NUM_CHANNELS, IMAGE_HEIGHT, IMAGE_WIDTH)\n                sample_image = sample_image.transpose((1, 2, 0))\n                # sample_image = sample_image * 0.5 + 0.5  # since we applied this normalization\n                # sample_image *= 255.0\n\n                ax[r, c].imshow(sample_image)\n\n                if sample_predictions is None:\n                    # show the actural labels in the cell title\n                    title = ax[r, c].set_title(\"%s\" % LABELS[sample_labels[image_index]])\n                else:\n                    # else check if prediction matches actual value\n                    true_label = sample_labels[image_index]\n                    pred_label = sample_predictions[image_index]\n                    prediction_matches_true = (true_label == pred_label)\n                    if prediction_matches_true:\n                        # if actual == prediction, cell title is prediction shown in green frot\n                        title = LABELS[true_label]\n                        title_color = 'g'\n                    else:\n                        # if actual != prediction, cell title is actual/prediction in red font\n                        title = '%s\\n%s' % (LABELS[true_label], LABELS[pred_label])\n                        title_color = 'r'\n                    # display cell title\n                    title = ax[r, c].set_title(title)\n                    plt.setp(title, color=title_color)\n        # set plot title, if one specified\n        if plot_title is not None:\n            f.suptitle(plot_title)\n\n        plt.show()\n        plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Class: Pairing Image Files with the Meta Data \nAlso, it will attach the data transformations information in order for data augmentation.","metadata":{}},{"cell_type":"code","source":"class HistoDataset(Dataset):\n    def __init__(self, image_paths, labels=None, ids=None, transforms=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.ids = ids\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Open a PIL image, apply transforms (if any) & convert to Numpy array\n        and return array and label at index\n        \"\"\"\n        image_path = self.image_paths[index]\n\n        img = Image.open(image_path)\n\n        img = self.transforms(img)\n\n        img_id = self.ids[index]\n        \n        if self.labels is not None:\n            label = self.labels[index]\n            return img, label, img_id     \n        \n        return img, img_id ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Augmentation\nTo enhance the robustness of our model, we will train it not only with the original image datasets but also with augmented data, including rotated, flipped, scaled, and resized images.\r\nMost importantly, the imagshasd to be converted into tensors foroure model to learnity.\r\nTorchvision''s transforms.Compo'se can sequentially and stochastically apply these transformation","metadata":{}},{"cell_type":"code","source":"# We are scaling all images to same size + converting them to tensors & normalizing data\nxforms = {\n    'train': transforms.Compose([\n        transforms.Resize((96,96)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomRotation(25),\n        transforms.RandomResizedCrop(96,scale=(0.8,1.0),ratio=(1.0,1.0)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n    ]),\n    'eval': transforms.Compose([\n        transforms.Resize((96,96)),\n        transforms.ToTensor(),\n    ]),    \n    'test': transforms.Compose([\n        transforms.Resize((96,96)),\n        transforms.ToTensor(),\n    ]),\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setting dataset for the dataloader  \nNow we actually are pairing the image data to its meta data with the function 'HistoDataset()'.  \nNote, all the datasets in the below cell are originated from 'Train' data only.  \nWe will touch the 'real' test dataset (/kaggle/input/test) when to submit our output.","metadata":{}},{"cell_type":"code","source":"# Define our datasets\n# Load data\n(X_train_paths, y_train, train_ids), (X_val_paths, y_val, val_ids), (X_test_paths, y_test, test_ids) = get_data()\n\ntrain_dataset = HistoDataset(X_train_paths, y_train, train_ids, xforms['train'])\neval_dataset = HistoDataset(X_val_paths, y_val, val_ids, xforms['eval'])\n# This 'test_dataset' below is divided from the 'Train' data.\ntest_dataset = HistoDataset(X_test_paths, y_test, test_ids, xforms['test'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Let's view a sample of 64 images \nloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\ndata_iter = iter(loader)\nsample_images, sample_labels, _ = next(data_iter)  # fetch first batch of 64 images & labels\nprint(f'Dataset: image.shape = {sample_images.shape}, labels.shape = {sample_labels.shape}')\ndisplay_sample(sample_images.cpu().numpy(), sample_labels.cpu().numpy(), plot_title=\"Sample Dataset Images\");     ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameters","metadata":{}},{"cell_type":"code","source":"IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS, NUM_CLASSES = 96, 96, 3, 2\n#NUM_EPOCHS, BATCH_SIZE, LR_RATE, L2_REG = 1, 256, 3e-3, 0.0075\nNUM_EPOCHS, BATCH_SIZE, LR_RATE, L2_REG = 100, 128, 3e-3, 0.0075","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Function: Building the Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    net = nn.Sequential(\n        nn.Conv2d(NUM_CHANNELS, 8, 3, padding=1),\n        nn.ReLU(),\n        nn.BatchNorm2d(8),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n        \n        nn.Conv2d(8, 16, 3, padding=1),\n        nn.ReLU(),\n        nn.BatchNorm2d(16),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n        \n        nn.Conv2d(16, 32, 3, padding=0),\n        nn.ReLU(),\n        nn.BatchNorm2d(32),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n        \n        nn.Conv2d(32, 64, 3, padding=0),\n        nn.ReLU(),\n        nn.BatchNorm2d(64),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n        \n        nn.Flatten(),\n        \n        nn.Linear(64*4*4, 512),\n        nn.ReLU(),\n        nn.Dropout(0.25),\n        \n        nn.Linear(512, NUM_CLASSES),\n        nn.LogSoftmax(dim=1)\n    )\n    model = net\n    class_counts = [num_benign, num_malignant]\n    weights = torch.FloatTensor(class_counts) / (num_benign + num_malignant)\n    weights = weights.cuda() if torch.cuda.is_available() else weights.cpu()\n\n    # since data is imbalanced, we need to apply weights to the loss function\n    criterion = nn.CrossEntropyLoss(weight=weights, reduction='sum')\n    #criterion = nn.NLLLoss(weight=weights, reduction='sum')\n    optimizer = optim.Adam(params=model.parameters(), lr=LR_RATE, weight_decay=L2_REG)\n\n    return model, criterion, optimizer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, criterion, optimizer = build_model()\n\nfrom torchinfo import summary\nprint(summary(model, input_size=(1, NUM_CHANNELS, IMAGE_HEIGHT, IMAGE_WIDTH))) # for batch_size = 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Function: Training ","metadata":{}},{"cell_type":"code","source":"# to record the training history\nhistory = {\n    'train_loss': [],\n    'val_loss': [],\n    'train_acc': [],\n    'val_acc': []\n}\n\n# device allocation\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n    model.to(device)\n    \n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print('-' * 20)\n\n        # Training Phase\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n\n        for inputs, labels, _ in tqdm(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            train_correct += (preds == labels).sum().item()\n            train_total += labels.size(0)\n\n        epoch_train_loss = train_loss / train_total\n        epoch_train_acc = train_correct / train_total\n        print(f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.4f}\")\n\n        # Validation Phase\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for inputs, labels, _ in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item() * inputs.size(0)\n                _, preds = torch.max(outputs, 1)\n                val_correct += (preds == labels).sum().item()\n                val_total += labels.size(0)\n\n        epoch_val_loss = val_loss / val_total\n        epoch_val_acc = val_correct / val_total\n        print(f\"Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.4f}\")\n\n        # Log history\n        history['train_loss'].append(epoch_train_loss)\n        history['val_loss'].append(epoch_val_loss)\n        history['train_acc'].append(epoch_train_acc)\n        history['val_acc'].append(epoch_val_acc)\n\n        # Learning Rate Scheduler Step\n\n        if scheduler:\n            scheduler.step(epoch_val_loss)\n\n    return model, history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Optimizing num_workers\n'Num_workers', the hyperparameter for the dataloader, set the number of cpu allocation. Unlike intuitive, allocating more workers does not necessarily increase the process speed.  \nLet's compare 2 workers (which normally works fine) and 4 workers.","metadata":{}},{"cell_type":"code","source":"# Check the CPU count\nimport os\nprint(f\"Kaggle CPU Count: {os.cpu_count()}\")\n#num_workers = os.cpu_count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n# measure time for different num_workers \n\ndef test_dataloader(num_workers):\n    start_time = time.time()\n\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n    val_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n    \n    # allocating model, loss function, and optimizer\n    model, criterion, optimizer = build_model()\n    lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n    #lr_scheduler = StepLR(optimizer, step_size=NUM_EPOCHS//5, gamma=0.5, verbose=1)\n    \n    # training model\n    model, history = train_model(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        criterion=criterion,\n        optimizer=optimizer,\n        scheduler=lr_scheduler,\n        num_epochs=NUM_EPOCHS    \n    )\n    end_time = time.time()\n    return end_time - start_time\n\n# test \ntime_2_workers = test_dataloader(num_workers=2)\ntime_4_workers = test_dataloader(num_workers=4)\n\nprint(f\"Time with 2 workers for {NUM_EPOCHS} epochs: {time_2_workers:.2f}s\")\nprint(f\"Time with 4 workers for {NUM_EPOCHS} epochs: {time_4_workers:.2f}s\")\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Running the above cell, results were the following;  \n・Time with 2 workers for 1 epoch: 836.04s  \n・Time with 4 workers for 1 epoch: 188.39s\n### Well, let's stick with 4 workers.","metadata":{}},{"cell_type":"code","source":"num_workers = 4 ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loader\nDataLoader will generate mini-batches from the dataset instances.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\nval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Let's build and train the model now!","metadata":{}},{"cell_type":"code","source":"# allocating model, loss function, and optimizer\nmodel, criterion, optimizer = build_model()\nlr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=1)\n#lr_scheduler = StepLR(optimizer, step_size=NUM_EPOCHS//5, gamma=0.5, verbose=1)\n\n# training model\nmodel, history = train_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=lr_scheduler,\n    num_epochs=NUM_EPOCHS    \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Function: Plotting the training history","metadata":{}},{"cell_type":"code","source":"def plot_training_history(history):\n    # Loss plot\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(history['train_loss'], label='Train Loss', marker='o')\n    plt.plot(history['val_loss'], label='Validation Loss', marker='o')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    # Accuracy Plot\n    plt.subplot(1, 2, 2)\n    plt.plot(history['train_acc'], label='Train Accuracy', marker='o')\n    plt.plot(history['val_acc'], label='Validation Accuracy', marker='o')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n\n    # Show the plots\n    plt.tight_layout()\n    plt.show()\n\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Function: Evaluating a model","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, dataloader, criterion):\n    model.to(device)\n    model.eval() # set the model in 'evaluation mode'\n\n    total_loss = 0.0\n    total_correct = 0\n    total_samples = 0\n\n    with torch.no_grad(): # disable gradient updates \n        for inputs, labels, _ in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # prediction \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # acummulate loss            \n            total_loss += loss.item() * inputs.size(0)\n\n            # count the number of correct\n            _, preds = torch.max(outputs, 1)\n            total_correct += (preds == labels).sum().item()\n            total_samples += labels.size(0)\n\n    # calculate average loss and accuracy\n    avg_loss = total_loss / total_samples\n    avg_acc = total_correct / total_samples\n    return avg_loss, avg_acc\n\n# evaluate on each dataset\ntrain_loss, train_acc = evaluate_model(model, train_loader, criterion)\nprint(f'Training data -> loss: {train_loss:.3f}, acc: {train_acc:.3f}')\n\neval_loss, eval_acc = evaluate_model(model, val_loader, criterion)\nprint(f'Cross-val data -> loss: {eval_loss:.3f}, acc: {eval_acc:.3f}')\n\ntest_loss, test_acc = evaluate_model(model, test_loader, criterion)\nprint(f'Testing data -> loss: {test_loss:.3f}, acc: {test_acc:.3f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# To save computing resources","metadata":{}},{"cell_type":"code","source":"# save the trained model\ntorch.save(model.state_dict(),\"/kaggle/working/model.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n# release the GPU memory by deleting the model object\n#del model\n\n# To reload the trained model;\n# initialize the model (with initial weights and biases)\nmodel, criterion, optimizer = build_model()\n\n# load the weights and biases into the model\nmodel.load_state_dict(torch.load(\"/kaggle/working/model.pth\"))\nmodel.to(device)\n\nfrom torchinfo import summary\nprint(summary(model, input_size=(1, NUM_CHANNELS, IMAGE_HEIGHT, IMAGE_WIDTH))) # for batch_size = 1\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Running Prediction","metadata":{}},{"cell_type":"code","source":"# Display sample from test dataset\nprint(f'Running predictions on {len(test_dataset)} test records...')\n\n#test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\nactuals, predictions = [], []\n\n# Ensure model is in evaluation mode\nmodel.eval()\n\nwith torch.no_grad(): # Disable gradient computation for inference\n    for batch_no, (images, labels, _) in enumerate(test_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Get predictions\n        outputs = model(images) # Forward pass\n        preds = torch.argmax(outputs, dim=1) # Get class indices\n\n        actuals.extend(labels.cpu().numpy().ravel())\n        predictions.extend(preds.cpu().numpy().ravel())\n\n# Convert lists to numpy arrays\nactuals = np.array(actuals)\npredictions = np.array(predictions)\n\nprint('Sample actual values & predictions...')\nprint('  - Actual values: ', actuals[:32])\nprint('  - Precictions  : ', predictions[:32])\n\n# Calculate accuracy\ncorrect_preds = (actuals == predictions).sum()\nacc = correct_preds / len(actuals)\nprint(f'  We got {correct_preds} of {len(actuals)} correct ({acc:.3f} accuracy)')\n\n# Display classification report and confusion matrix\nprint(classification_report(actuals, predictions))\nprint('Confusion Matrix:')\nprint(confusion_matrix(actuals, predictions))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Actual/Prediction Visualizer\nIf sample_predictions are provided, then each cell's title displays the prediction (if it matches actual) in green color, or actual/prediction if there is a mismatch, in red color.","metadata":{}},{"cell_type":"code","source":"test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\ndata_iter = iter(test_loader)\n\nimages, labels, _ = next(data_iter)\n\n# model prediction\nimages = images.to(device) \npreds = model(images)\npreds = torch.argmax(preds, dim=1).cpu().numpy()\n\n# print the result\nprint(images.shape, labels.shape, preds.shape)\n\n# plot the sample\ndisplay_sample(images.cpu().numpy(), labels.cpu().numpy(), sample_predictions=preds,\n               grid_shape=(8, 8), fig_size=(16, 20), plot_title='Sample Predictions')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission.csv Generator\n\nHere we will start handling the 'real' test data in (/kaggle/input).  \nLet's check the raw test data; how many files do we have.","metadata":{}},{"cell_type":"code","source":"# Set directory where the test data is\nTEST_DATA_DIR = '/kaggle/input/histopathologic-cancer-detection/test'\n\n# Real test dataset; we call it z_test_dataset\nz_test_images = [f for f in os.listdir(TEST_DATA_DIR) if f.endswith('.tif')]\nprint(f'Number of z_test_images: {len(z_test_images)}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Retrieve path and ids from z_test datasets\nz_test_paths = []\nz_test_ids = []\n\nfor f in os.listdir(TEST_DATA_DIR):\n    z_test_paths.append(os.path.join(TEST_DATA_DIR, f)) # full path\n    z_test_ids.append(os.path.splitext(f)[0]) # file name excluded '.tif'\n\n# Prepare the dataset to feed dataloader\nz_test_dataset = HistoDataset(z_test_paths, ids=z_test_ids, transforms=xforms['test'])\nz_test_loader = DataLoader(z_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n\n# Ensure model is in evaluation mode\nmodel.eval()\n\n# Store predictions\npredictions = []\nimage_ids = [] \n\n# Generate predictions\nwith torch.no_grad():\n    for batch_no, (images, ids) in enumerate(z_test_loader):\n        images = images.to(device)\n\n        # Get predictions\n        outputs = model(images)\n        preds = torch.argmax(outputs, dim=1)\n\n        # Append results\n        predictions.extend(preds.cpu().numpy())\n        image_ids.extend(ids) \n\n# Create a submission DataFrame\nsubmission = pd.DataFrame({\n    'id': image_ids,\n    'label': predictions\n})\n\n# Save to CSV\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file created: submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ntrue_sub = pd.read_csv('/kaggle/working/submission.csv')\nprint(true_sub.shape)\ntrue_sub[:10]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\n\nThe primary code in this notebook is based on references to the GitHub page by Manish Bhobe.\r\n\r\nThe reason why this CNN achieves high accuracy despite its simple design is, in my opinion, due to Manish Bhobe’s meticulous focus on data preprocessing and hyperparameter tuning.\r\n\r\nWhat his code teaches us is that in data science, the star of the show isn’t model building but the data itself. By carefully \"cooking\" the data, even simple models can deliver high-performance accuracy.\r\n\r\nAdditionally, his viewer-friendly code—such as visualizing prediction results with their corresponding labels—greatly enhances viewers' understanding and analysis.\r\n\r\nThe practice of saving and deleting models to improve memory efficiency and eliminate wasteful memory usage is another notable aspect.\r\n\r\nFor future endeavors, I plan to work on my own hyperparameter tuning, delve into the design of VGG and ResNet, and, after understanding Transformers, take on ViT.\r\n\r\nThank you for reading this notebook.\r\n","metadata":{}},{"cell_type":"markdown","source":"# Resources\nHistopathological Cancer Detection - Binary Classification Kaggle Challenge by Manish Bhobe\nhttps://github.com/mjbhobe/dl-pytorch/blob/master/Pytorch%20-%20Histopathology%20Detection%20-%20Binary%20Classification.ipynb","metadata":{}}]}